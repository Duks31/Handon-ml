![](./Autoencoders.png)

# Exercise

1. What are the main tasks that autoencoders are used for?

2. Suppose you want to train a classifier and you have plenty of unlabeled training data, but only a few thousand labeled instance. How can autoencoders help? How would you proceed?

3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoders? How can you evaluate the performance of an autoencoder?

4. What are undercomplete an overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomeplete autoencoder?

5. How do you tie weights in a stacked autoencoder? What is the point of doing so?

6. What is a common technique to visualize features learned by the lower layer of a stacked autocoder? What about higher layers?

7. What is a generative model? Can you name a type of generative autoencoder?
